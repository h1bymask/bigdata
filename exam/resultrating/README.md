# Программа экзамена по курсу Большие данные
При подготовке на экзамене разрешается пользоваться интернетом и средой разработки, но тогда к сдаче билета вся информация должна быть переписана только на листы бумаги.
Чем больше пунктов в теме, тем короче ожидается рассказ по каждому из них.
Задачи будут даваться из разделов, отмеченных знаком \* справа.

## Понятие больших данных
Признаки больших данных. Численные и маркетинговые характеристики больших данных. Их промышленное применение. Большие данные в космических исследованиях.
## Понятие науки о данных
Большие наборы данных. Анализ данных. Маркетинговая аналитика. Интеллектуальный анализ данных.
## Обработка больших данных
Особенности архитектуры систем обработки больших данных. Параллельное выполнение, распределение запросов. MapReduce. Диспетчеризация и синхронизация запросов, консолидация результатов. Управление ошибками и отказами. Идемпотентность.
## Хранение и анализ больших данных
Понятие распределенного хранилища. HDFS в Apache Hadoop. Сериализация данных. JSON. RPC. Выполнение кода на узле хранения данных. Apache AVRO.
## БД в больших данных
Требования ACID к обычным БД: атомарность, согласованность, изолированность, устойчивость/прочность. Понятия хранения строк (SQL и AVRO) и хранения столбцов (Parquet/ORC) в БД. Распределенные БД и требования BASE к NOSQL (доступность, гибкость, согласованность в итоге). Эвристическая теорема Брюера CAP о согласованности, доступности и устойчивости к разделению. Примеры баз данных NOSQL и цель их использования; Apache Hive и HiveQL. Применение Apache Sqoop.
## Инструменты хранения больших данных*
Хранение больших данных в Apache AVRO, Parquet, ORC, Hive. Импорт и экспорт данных; Apache Scoop.
## Инструменты обработки больших данных*
MapReduce в Hadoop; hadoop-streaming. Обработка данных с помощью Apache Spark: PySpark, RDD (Resilient Distributed Dataset), parallelize.
## Применение инструментов анализа данных для обработки больших данных*
Особенности применения Pandas для обработки в HDFS. Кластеризация и K-means в PySpark.
## Схожесть данных и уменьшение размерности данных
Группы (bucket). Метрики схожести: сходство по Жаккару, расстояние Левенштейна (редактирования), расстояние по Хэммингу, Евклидово расстояние, коэффициент Отиаи (косинусный). Понятие локально-чувствительного хэширования; подписи (хэши) множеств. Характеристическая матрица для множеств.
## Хэширование и сходство по Жаккару
Сложность вычисления пересечения множеств. Алгоритм независимых по минимуму перестановок MinHash локально-чувствительного хэширования: вычисление хэша hmin(S) множества S, вычисление сигнатуры Hmin k независимых хэш-функций множества S, случайные перестановки, h(perm(x)) для x ∈ S, величина ошибки и вероятность близости. MinHashLSH в PySpark. Поиск соседей.
## Применение локально-чувствительного хэширования для поиска ближайших соседей
Построение хэш-таблиц. Случайная проекция, Лемма Джонсона-Линденштрауса и расстояние Евклида. BucketedRandomProjectionLSH в PySpark. Алгоритм K-means, центроиды, итеративный алгоритм вычисления.
## Инструменты вычисления локально-чувствительных хэшей и поиса соседей*
Группы (bucket). Метрики схожести. BucketedRandomProjectionLSH и MinHashLSH в PySpark. Поиск соседей.
